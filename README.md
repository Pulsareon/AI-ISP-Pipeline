# AI-ISP Pipeline

> **"æˆ‘ä»¬è¿™ä¸€ä»£ç¨‹åºå‘˜å°±åƒæ˜¯æ±‡ç¼–å˜æˆCï¼Œä»Žcoderå˜æˆediterã€‚"**

An end-to-end Image Signal Processing (ISP) pipeline designed for AI-based computational photography.

## ðŸš€ Features

- **Frame Selection**: Laplacian Variance based sharpness scoring.
- **Alignment**: ECC (Enhanced Correlation Coefficient) image alignment.
- **Demosaicing**: Standard Bayer to RGB conversion.
- **Denoising**: NLM (Non-local Means) with interface for Deep Learning models (DnCNN/UNet).
- **Enhancement**: CLAHE (Contrast Limited Adaptive Histogram Equalization) and Texture Sharpening.

## ðŸ“‚ Project Structure

```
AI-ISP/
â”œâ”€â”€ pipeline.py       # Core ISP logic (Python Prototype)
â”œâ”€â”€ pipeline_lite.py  # High-Performance Tiling Logic
â”œâ”€â”€ simulate_raw.py   # Physical Sensor Simulator
â”œâ”€â”€ ncnn_src/         # C++ Implementation (ncnn + OpenCV)
â”œâ”€â”€ scripts/          # Deep Learning Workflow (PyTorch -> ONNX)
â”‚   â”œâ”€â”€ model.py      # TinyISPNet Definition
â”‚   â”œâ”€â”€ export.py     # ONNX Exporter
â”‚   â””â”€â”€ inference.py  # ONNX Runtime Inference Engine
â””â”€â”€ requirements.txt
```

## ðŸ› ï¸ Usage

### 1. Python Simulation
```bash
pip install opencv-python numpy
python pipeline.py
```

### 2. Deep Learning Demo (PyTorch -> ONNX)
We provide a complete workflow to train, export, and run a TinyISPNet.

**Export to ONNX:**
```bash
python scripts/export.py
```

**Run Inference:**
```bash
python scripts/inference.py
```
This runs the ISP pipeline on `input_bayer.png` (auto-generated) and saves `output.png`.

### 4. RAW Processing (MIPI RAW10)
To handle real-world sensor data, we provide a RAW10 pack/unpack utility compliant with MIPI CSI-2 standards.

```bash
python scripts/raw_processing.py
```
This validates the bit-level manipulation logic required for interfacing with mobile sensors.

### 5. Test Gallery (Real-world Validation)

We have validated the TinyISPNet (Sharpening variant) on various scene types.
Results are saved in `results/` as side-by-side comparisons (Original Left vs AI Output Right).

| Scene Type | Source | Purpose | Output File |
|------------|--------|---------|-------------|
| **Landscape** | Unsplash | Test distant detail recovery | `results/compare_landscape.jpg` |
| **City** | Unsplash | Test geometric edge enhancement | `results/compare_city.jpg` |
| **Portrait** | Unsplash | Test skin texture preservation | `results/compare_portrait.jpg` |
| **Texture** | Unsplash | Test high-frequency detail restoration | `results/compare_texture.jpg` |

**Validation Metric:**
- Laplacian Variance Improvement: **> +3000%** (on blurred synthetic input)

## ðŸ”§ Modular Architecture (Ref. openISP)

In response to Issue #1, we have refactored the pipeline into a modular design.

- **`pipeline_v2.py`**: A clean, modular ISP pipeline (BLC -> Demosaic -> CCM -> Gamma -> AI-NR).
- **`scripts/model.py`**: Added **DnCNN** implementation for state-of-the-art AI Denoising.

Run the modular pipeline:
```bash
python pipeline_v2.py
```

## ðŸ“œ License
MIT
